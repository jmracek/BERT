.version 6.4
.target sm_70
.address_size 64

#define WAIT_ALL_THREADS 0xffffffff

/* mmultShmemTiles
*
* This function is a PTX wrapper around the 4 mma.sync instructions required to compute a 32x32 block of A * B.  
*
* ARGS:
*   ptr_a:  Pointer to the 128-bits of shared memory containing the 8 fp16 elements of the A matrix
*           needed by the current thread in performing the 4 mma.sync operations.
*   ptr_b:  Pointer to the 128-bits of shared memory containing the 8 fp16 elements of the B matrix
*           needed by the current thread in performing the 4 mma.sync operations
*   acc:    This is an array in local memory containing the 8 elements of the accumulator, for each
*           of the 4 mma.sync operations.
*/
// Probably need to set alignment by .ptr.global.align 32
.visible .func mmultShmemTiles( 
    .param .u64 ptr_a, 
    .param .u64 ptr_b, 
    .param .u64 qp0_acc_03,
    .param .u64 qp0_acc_47,
    .param .u64 qp1_acc_03,
    .param .u64 qp1_acc_47,
    .param .u64 qp2_acc_03,
    .param .u64 qp2_acc_47,
    .param .u64 qp3_acc_03,
    .param .u64 qp3_acc_47
) {
    // Load the A, B pointers into registers
    .reg .u64 rptr_a, rptr_b;
    ld.param.u64 rptr_a, [ptr_a];
    ld.param.u64 rptr_b, [ptr_b];

    // Declare all the registers we need for this computation
    .reg .f16x2     %Ra<4>, %Rb<4>;
    .reg .f32       %Rc<8>, %Rd<8>, %Re<8>, %Rf<8>;
    
    // Load A and B matrices from SHMEM into registers
    ld.shared.v4.b32 {%Ra0, %Ra1, %Ra2, %Ra3}, [rptr_a];
    bar.warp.sync WAIT_ALL_THREADS;
    ld.shared.v4.b32 {%Rb0, %Rb1, %Rb2, %Rb3}, [rptr_b];
    bar.warp.sync WAIT_ALL_THREADS;
    
    .reg .u64 %qptr<8>;
    ld.param.u64 %qptr0, [qp0_acc_03];
    ld.param.u64 %qptr1, [qp0_acc_47];
    ld.param.u64 %qptr2, [qp1_acc_03];
    ld.param.u64 %qptr3, [qp1_acc_47];
    ld.param.u64 %qptr4, [qp2_acc_03];
    ld.param.u64 %qptr5, [qp2_acc_47];
    ld.param.u64 %qptr6, [qp3_acc_03];
    ld.param.u64 %qptr7, [qp3_acc_47];

    // Load all accumulators into registers
    ld.v4.f32 {%Rc0, %Rc1, %Rc2, %Rc3}, [%qptr0];
    ld.v4.f32 {%Rc4, %Rc5, %Rc6, %Rc7}, [%qptr1]; 
    ld.v4.f32 {%Rd0, %Rd1, %Rd2, %Rd3}, [%qptr2];
    ld.v4.f32 {%Rd4, %Rd5, %Rd6, %Rd7}, [%qptr3];
    ld.v4.f32 {%Re0, %Re1, %Re2, %Re3}, [%qptr4];
    ld.v4.f32 {%Re4, %Re5, %Re6, %Re7}, [%qptr5];
    ld.v4.f32 {%Rf0, %Rf1, %Rf2, %Rf3}, [%qptr6];
    ld.v4.f32 {%Rf4, %Rf5, %Rf6, %Rf7}, [%qptr7];
    
    // Perform the four mma.sync operations for the first half of the shmem tile
    // * -
    // - -
    mma.sync.aligned.m8n8k4.col.row.f32.f16.f16.f32 
        {%Rc0, %Rc1, %Rc2, %Rc3, %Rc4, %Rc5, %Rc6, %Rc7},
        {%Ra0, %Ra1},
        {%Rb0, %Rb1},
        {%Rc0, %Rc1, %Rc2, %Rc3, %Rc4, %Rc5, %Rc6, %Rc7};

    // - *
    // - -
    mma.sync.aligned.m8n8k4.col.row.f32.f16.f16.f32 
        {%Rd0, %Rd1, %Rd2, %Rd3, %Rd4, %Rd5, %Rd6, %Rd7},
        {%Ra0, %Ra1},
        {%Rb2, %Rb3},
        {%Rd0, %Rd1, %Rd2, %Rd3, %Rd4, %Rd5, %Rd6, %Rd7};
    
    // - -
    // * -
    mma.sync.aligned.m8n8k4.col.row.f32.f16.f16.f32 
        {%Re0, %Re1, %Re2, %Re3, %Re4, %Re5, %Re6, %Re7},
        {%Ra2, %Ra3},
        {%Rb0, %Rb1},
        {%Re0, %Re1, %Re2, %Re3, %Re4, %Re5, %Re6, %Re7};
    
    // - -
    // - *
    mma.sync.aligned.m8n8k4.col.row.f32.f16.f16.f32 
        {%Rf0, %Rf1, %Rf2, %Rf3, %Rf4, %Rf5, %Rf6, %Rf7},
        {%Ra2, %Ra3},
        {%Rb2, %Rb3},
        {%Rf0, %Rf1, %Rf2, %Rf3, %Rf4, %Rf5, %Rf6, %Rf7};

    // Now update each of the accumulators 
    st.v4.f32 [%qptr0], {%Rc0, %Rc1, %Rc2, %Rc3};
    st.v4.f32 [%qptr1], {%Rc4, %Rc5, %Rc6, %Rc7};
    st.v4.f32 [%qptr2], {%Rd0, %Rd1, %Rd2, %Rd3};
    st.v4.f32 [%qptr3], {%Rd4, %Rd5, %Rd6, %Rd7};
    st.v4.f32 [%qptr4], {%Re0, %Re1, %Re2, %Re3};
    st.v4.f32 [%qptr5], {%Re4, %Re5, %Re6, %Re7};
    st.v4.f32 [%qptr6], {%Rf0, %Rf1, %Rf2, %Rf3};
    st.v4.f32 [%qptr7], {%Rf4, %Rf5, %Rf6, %Rf7};

    ret;
}
